---
title: "H2O Deployment"
date: today
author: James Bristow
fig-pos: 'H'
toc: true
lof: true
lot: true
link-citations: true
---

# Introduction

This tutorial will demonstrate how one may fit and deploy an H2O machine learning model onto Kubernetes via vetiver. We first load all required dependencies.

```{r setup, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = FALSE, output=TRUE, eval=TRUE}

box::use(../../R/tidymodels_deployment)
box::use(
  readr[read_csv, read_file],
  here[here],
  rsample[initial_split, training, testing],
  parsnip[auto_ml, set_engine, set_mode],
  recipes[recipe, update_role, step_zv, step_nzv, step_normalize, step_impute_knn, update, all_numeric, all_outcomes],
  hardhat[tune],
  workflows[workflow, add_recipe, add_model, fit],
  vetiver[vetiver_model, vetiver_pin_write, vetiver_api, vetiver_pin_read],
  pins[board_temp, board_s3, pin_write, pin_read, pin_upload, pin_download],
  readr[read_file],
  paws.common,
  paws.storage,
  plotly[ggplotly],
  probably[int_conformal_split, cal_plot_regression],
  plumber[pr, pr_run],
  zeallot[...],
  targets[tar_make],
  h2o[h2o.connect],
  agua[extract_fit_parsnip, rank_results, member_weights],
  dplyr[filter, arrange, mutate],
  ggplot2[ggplot, geom_boxplot, labs, scale_x_sqrt, aes],
  tidyr[unnest]
)

h2o.connect(
  ip = "h2o.k8s.dev.co.nz", port = 443, https = TRUE
)
```

# Data

We next load the mtcars dataset, and perform data pre-processing.

```{r load-h2o-data, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, output=TRUE, eval=TRUE}

data("mtcars")

data_split <- mtcars |>
  initial_split(
    prop = 0.9
  )

data_train <- training(data_split)
data_test  <- testing(data_split)

training_recipe <- recipe(data_train) |>
  update_role(everything(), new_role = "predictor") |>
  update_role(mpg, new_role = "outcome") |>
  step_zv() |>
  step_nzv() |>
  step_normalize(all_numeric(), -all_outcomes()) |>
  step_impute_knn()
```

# AutoML

We next train an ensemble using AutoML.

```{r h2o-automl, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, output=TRUE, eval=TRUE}

auto_spec <-
  auto_ml() |>
  set_engine("h2o", max_runtime_secs = 10, seed = 1) |>
  set_mode("regression")

auto_wflow <-
  workflow() |>
  add_model(auto_spec) |>
  add_recipe(training_recipe)

auto_fit <- fit(auto_wflow, data = data_train)
extract_fit_parsnip(auto_fit)

```

## Results

We next view the results of the AutoML algorithm.

```{r h2o-automl-results, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, output=TRUE, eval=TRUE}

rank_results(auto_fit) |>
  filter(.metric == "mae") |>
  arrange(rank)

```

```{r fig-h2o-local, results = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, output=TRUE, eval=TRUE}
#| fig-cap: H20 Ensemble importances.

p <- auto_fit |>
  extract_fit_parsnip() |>
  member_weights() |>
  unnest(importance) |>
  filter(type == "scaled_importance") |>
  ggplot() +
  geom_boxplot(aes(value, algorithm)) +
  scale_x_sqrt() +
  labs(y = NULL, x = "scaled importance", title = "Member importance in stacked ensembles")

ggplotly(p)
```

# Conformalisation

We next conformalise the AutoML model to produce non-parametric prediction intervals.

```{r h2o-conformalisation, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, output=TRUE, eval=TRUE}
conformalised_stack <- int_conformal_split(auto_fit, data_train)
conformalised_stack$training <- data_train
predict(conformalised_stack, new_data = data_test)
```

```{r fig-conformal-ensemble-work-calibration, include = TRUE, echo = FALSE, message = FALSE, warning = FALSE, cache = TRUE, output=TRUE, eval=TRUE}
#| fig-cap: Calibration plot of observed and predicted discrepancies on testing data.

p <- conformalised_stack |>
  predict(new_data = data_test, level = 0.95) |>
  mutate(
    mpg = data_test$mpg
  ) |>
  cal_plot_regression(truth = mpg, estimate = .pred) 

ggplotly(p)
```

# Model deployment

Let's save the model to S3. Then deploy it.

```{r h2o-s3, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, output=TRUE, eval=FALSE}

board <- board_s3(
  "data", 
  access_key = "user", 
  secret_access_key = "password", 
  region = "us-east-2",
  endpoint = "https://minio-api.k8s.dev.co.nz"
)

vetiver_create_description.int_conformal_split <- function(model) {
    "A conformalised machine learning model."
}

vetiver_ptype.int_conformal_split <- function(model, ...) {
    vctrs::vec_ptype(model$training)
}

handler_predict.int_conformal_split <- function(vetiver_model, ...) {
    
    ptype <- vetiver_model$prototype
    
    function(req) {
        newdata <- req$body
        newdata <- vetiver::vetiver_type_convert(newdata, ptype)
        newdata <- hardhat::scream(newdata, ptype)
        ret <- predict(vetiver_model$model, new_data = newdata, ...)
        list(.pred = ret)
    }
    
}

vetiver_create_meta.int_conformal_split <- function(model, metadata) {
    vetiver::vetiver_meta(metadata, required_pkgs = "probably")
}

v_conformalised_stack <- vetiver_model(conformalised_stack, "conformalised_h2o_stack")
board |> 
  vetiver_pin_write(v_conformalised_stack)

v_model <- board |> vetiver_pin_read("conformalised_h2o_stack")

pr(here("book", "h2o_deployment/app/plumber.R")) |>
  vetiver_api(v_model) |>
  pr_run(port = 8088)
```

# H2O with DALEX

This section demonstrates how to fit an H2O model on `mtcars`, and then explain the model using DALEX. We use `mpg` as the target and all other variables as predictors. This framework works with ML models, including H2O, random forests, xgboost, or even linear models.

```{r setup-dalex, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = FALSE, output=TRUE, eval=TRUE}
box::use(
  h2o[h2o.init, h2o.gbm, h2o.predict, as.h2o],
  DALEX[explain, model_parts, model_profile],
  dplyr[mutate],
  ggplot2[ggplot],
  plotly[ggplotly]
)

h2o.init()

```

## Data for DALEX demo

Prepare the `mtcars` dataset for modeling and explanation, and convert the data to H2O dataframe.

```{r data_for_DALEX, include  = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = FALSE, output = TRUE, eval = TRUE}
y <- "mpg"
x <- setdiff(names(mtcars), y)

mtcars_h2o <- as.h2o(mtcars)
```

## H2O GBM model

Now train a simple H2O GBM regression model on `mtcars`.

```{r H2O_GBM_Model, include  = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = FALSE, output = TRUE, eval = TRUE}
model_h2o <- h2o.gbm(
  y = y,
  x = x,
  training_frame = mtcars_h2o,
  seed = 123
)
```

## DALEX explainer

We next create a DALEX explainer for the GBM H2O model.
In DALEX, an explainer object provides a unified interface to understand and interpret any machine learning model and acts as a wrapper around the trained model, containing:

- The model object itself

- data used to explain the model

- true target values

- a optional custom predict function 

Once created, this explainer enables computation of :

- variable importance (feature impact)

- partial dependence profiles (effect of variables)

- residual diagnostics

- local explanations (e.g., individual predictions)

```{r DALEX_explainer, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = FALSE, output = TRUE, eval = TRUE}
predict_function <- function(model, data) {
  as.vector(h2o.predict(model, as.h2o(data)))
}

explainer <- explain(
  model = model_h2o,
  data = mtcars[, x],
  y = mtcars$mpg,
  predict_function = predict_function,
  label = "H2O GBM"
)
```

## Variable importance

```{r variable_importance, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = FALSE, output = TRUE, eval = TRUE}

vi <- model_parts(explainer)
plot(vi)
```

## Partial dependence profile

```{r partial_dep_profile, fig-cap: Partial dependence profile of horsepower.}
pdp_hp <- model_profile(explainer, variables = "hp")

p <- plot(pdp_hp)
ggplotly(p)
```

# Run with targets

We can run the above as a targets pipeline.

```{r tidymodels-targets, include = TRUE, echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE, output=TRUE, eval=FALSE}

tar_make(
  script = here("pipelines", "_targets_h2o_deployment.R")
)
```
