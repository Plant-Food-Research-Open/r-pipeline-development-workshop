---
title: "Model Card: Stan (brms)"
date: '`r Sys.Date()`'
output: 
  html_document
params:
    name: multilevel_brms_fit
    version: NULL
---

```{r, echo = FALSE, output=TRUE, eval=TRUE}
library(vetiver)
library(pins)
library(yardstick)
knitr::opts_chunk$set(echo = FALSE)

board <- board_s3(
  "data", 
  access_key = "user", 
  secret_access_key = "password", 
  region = "us-east-2", 
  endpoint = "https://minio-api.pfram.k8s.dev.pfr.co.nz"
)

v <- vetiver_pin_read(board, params$name, version = params$version)
v_meta <- pin_meta(board, params$name)

box::use(
  ggplot2[theme_set, theme_light],
  readr[read_csv, read_file],
  here[here],
  rsample[initial_split, training, testing],
  parsnip[linear_reg, set_engine, set_mode],
  recipes[recipe, update_role, step_zv, step_nzv, step_normalize, step_impute_knn, update, all_numeric, all_outcomes, add_role],
  hardhat[tune],
  workflows[workflow, add_recipe, add_model, fit, add_variables, remove_variables],
  vetiver[vetiver_model, vetiver_pin_write, vetiver_api, vetiver_pin_read],
  pins[board_temp, board_s3, pin_write, pin_read, pin_upload, pin_download],
  readr[read_file],
  paws.common,
  paws.storage,
  plotly[ggplotly],
  plumber[pr, pr_run],
  zeallot[...],
  targets[tar_make],
  dplyr[filter, arrange, mutate, select],
  ggplot2[ggplot, geom_boxplot, labs, scale_x_sqrt, aes],
  tidyr[unnest],
  multilevelmod,
  brms[brm, bf, prior, threading, save_pars],
  loo,
  cmdstanr[cmdstan_model],
  rstanarm[normal],
  marginaleffects[plot_predictions, plot_slopes],
  bayesplot[ppc_dens_overlay, ppc_intervals, ppc_stat]
)
theme_set(theme_light())

```

A [model card](https://doi.org/10.1145/3287560.3287596) provides brief, transparent, responsible reporting for a trained machine learning model.

## Model details

-   Developed by PERSON AND/OR TEAM
-   `r cli::pluralize("{v$description} using {ncol(v$prototype)} feature{?s}")`
-   More details about how model was developed and what it is predicting
-   More details on feature engineering and/or data preprocessing for model
-   Version `r v$metadata$version` of this model was published at `r v_meta$created`
-   Citation and/or license details for the model
-   If you have questions about this model, please contact [PERSON\@ORG.ORG](mailto:PERSON@ORG.ORG){.email}

## Intended use

-   The primary intended uses of this model are ...
-   The primary intended users of this model are ...
-   Some use cases are out of scope for this model, such as ...

## Important aspects/factors

-   Aspects or factors (demographic, environmental, technical) that are relevant to the context of this model are ...
-   In evaluating this model, we examined aspects such as ...

## Metrics

-   The metrics used to evaluate this model are ...
-   These metrics are computed via ...
-   We chose these metrics because ...

## Training data & evaluation data

-   The training dataset for this model was ...

-   The training dataset for this model has the "prototype" or signature:

```{r, eval=TRUE}
dplyr::glimpse(v$prototype)
```

-   The evaluation dataset used in this model card is ...

-   We chose this evaluation data because ...

```{r, eval=TRUE}
## EVALUATION DATA:

df <- v$model$training |>
  dplyr::bind_cols(v$model$response)

## consider using a package like skimr or DataExplorer for automated 
## presentation of evaluation data characteristics
```

## Quantitative analyses {.tabset}

```{r, eval=TRUE}
## compute predictions for your evaluation data
## load packages needed for prediction:
library(parsnip)
library(workflows)
library(probably)
preds <- predict(v, df) |>
  dplyr::bind_cols(df)

preds  
```

### Overall model performance

```{r, eval=TRUE}
preds |>
    metrics(cum, Estimate)
```

### Visualize model performance

```{r, fig.height=3, eval=TRUE}
library(ggplot2)
p <- preds |>
    ggplot(aes(cum, Estimate)) +
    geom_abline(slope = 1, lty = 2, color = "darkblue", size = 1.2) +
    geom_point(alpha = 0.5, show.legend = FALSE) +
    geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), fill = "lightblue", alpha = 0.2)

plotly::ggplotly(p)
```

## Ethical considerations

-   We considered ...

## Caveats & recommendations

-   This model does ...
-   This model does not ...
-   We recommend ...
